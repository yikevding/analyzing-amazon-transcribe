# QTM350-Final

If you are an Amazon Alexa user, maybe you have noticed that Alexa can sometimes understand people's questions more precisely than other times, and sometimes two people ask Alexa the exact same question might get two totally different answers. For instance, two people ask Alexa the same questions, "what's the weather outside?" or "tell me the location of the nearest hospital", might get totally different responses. In this project, we are interested in "how do people with different accent (native and non-native speakers) influence the performance of Amazon Transcribe?", and we specifically look at how two variables, accent and biological sex, influence the performance of Amazon Transcribe.

If you are interested in learning the motivation, experimental design, dataset description, data extraction, data analysis, data visualization, and other details about our project, you can check out our project blog: ***https://final-resources.s3.amazonaws.com/QTM350FinalProjectBlog-FinalVersion.html***.

This repository contains all the data and analysis we use in our project. Below is the list of all the materials contained in this project.
* JupyterNotebook: This folder contains all the work we have done in jupyter notebook, such as data analysis and data visualization.
* final-resources: This folder contains all the recordings we have collected for this project.
* finalConfidence: This folder contains all the confidence information generated by Amazon Transcrive when transcribing the input audio.
* finalJson: This folder contains all the Json files used in the data analysis part.
* finalTranscription: This folder contains all the txt files used in comparing input text with sample text.
* Accuracy.csv: This file contains the transcribe accuracy we calculated for each input text.
* proposalrecording.mp4: This is a video of our project proposal.

If you have any question or suggestions about our project, please feel free to reach out to us. 
